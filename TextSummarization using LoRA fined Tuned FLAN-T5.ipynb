{"cells":[{"cell_type":"markdown","source":["https://github.com/Ryota-Kawamura/Generative-AI-with-LLMs/blob/main/Week-2/Lab_2_fine_tune_generative_ai_model.ipynb"],"metadata":{"id":"yXwdCI3QZ3iK"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"hUcRlh9mVHKl","outputId":"5ce458b1-ff06-442e-df8a-4fb8bbb24081"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n","Collecting pip\n","  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n","Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 24.1.2\n","    Uninstalling pip-24.1.2:\n","      Successfully uninstalled pip-24.1.2\n","Successfully installed pip-24.3.1\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m690.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m144.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cpu requires torch==2.5.1, but you have torch 1.13.1 which is incompatible.\n","torchvision 0.20.1+cpu requires torch==2.5.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.11.0)\n","Collecting datasets\n","  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (2024.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n","Collecting fsspec\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.11)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n","Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","Installing collected packages: fsspec, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.12.0\n","    Uninstalling fsspec-2024.12.0:\n","      Successfully uninstalled fsspec-2024.12.0\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 2.11.0\n","    Uninstalling datasets-2.11.0:\n","      Successfully uninstalled datasets-2.11.0\n","Successfully installed datasets-3.2.0 fsspec-2024.9.0\n"]}],"source":["%pip install --upgrade pip\n","%pip install --disable-pip-version-check \\\n","    torch==1.13.1 \\\n","    torchdata==0.5.1 --quiet\n","\n","%pip install \\\n","    transformers==4.27.2 \\\n","    datasets==2.11.0 \\\n","    evaluate==0.4.0 \\\n","    rouge_score==0.1.2 \\\n","    loralib==0.1.1 \\\n","    peft==0.3.0 --quiet\n","\n","%pip install -U datasets huggingface_hub fsspec"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"B_h48qlEVgPi","outputId":"2474c2ab-b34d-4ed9-9b81-7b09423f244c"},"outputs":[{"ename":"RuntimeError","evalue":"Failed to import transformers.training_args because of the following error (look up to see its traceback):\n/usr/local/lib/python3.10/dist-packages/_XLAC.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZNK5torch4lazy17LazyGraphExecutor16ShouldSyncTensorERKN3c1013intrusive_ptrINS0_10LazyTensorENS2_6detail34intrusive_target_default_null_typeIS4_EEEE","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1125\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_xla/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0m_XLAC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: /usr/local/lib/python3.10/dist-packages/_XLAC.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZNK5torch4lazy17LazyGraphExecutor16ShouldSyncTensorERKN3c1013intrusive_ptrINS0_10LazyTensorENS2_6detail34intrusive_target_default_null_typeIS4_EEEE","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-5cc066d19b9c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenerationConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   1129\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 \u001b[0;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.training_args because of the following error (look up to see its traceback):\n/usr/local/lib/python3.10/dist-packages/_XLAC.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZNK5torch4lazy17LazyGraphExecutor16ShouldSyncTensorERKN3c1013intrusive_ptrINS0_10LazyTensorENS2_6detail34intrusive_target_default_null_typeIS4_EEEE"]}],"source":["from datasets import load_dataset\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n","import torch\n","import time\n","import evaluate\n","import pandas as pd\n","import numpy as np\n","\n","## HF_TOKEN : authentication is recommended but still optional to access public models or datasets."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"iuDV-xfGVkAD"},"outputs":[],"source":["huggingface_dataset_name = \"knkarthick/dialogsum\"\n","dataset = load_dataset(huggingface_dataset_name)\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"gj6UgrF2VsD7"},"outputs":[],"source":["# Load the pre-trained FLAN-T5 model and its tokenizer directly from HuggingFace.\n","# We will be using the small version of FLAN-T5.\n","# Setting torch_dtype=torch.bfloat16 specifies the memory type to be used by this model.\n","\n","model_name='google/flan-t5-small'\n","\n","original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XbVhmLG_Y6ZL"},"outputs":[],"source":["def print_number_of_trainable_model_parameters(model):\n","    trainable_model_params = 0\n","    all_model_params = 0\n","    for _, param in model.named_parameters():\n","        all_model_params += param.numel()\n","        if param.requires_grad:\n","            trainable_model_params += param.numel()\n","    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n","\n","print(print_number_of_trainable_model_parameters(original_model))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SbeMIUVuY90i"},"outputs":[],"source":["display(dataset['test'][1]['dialogue'])\n","print()\n","display(dataset['test'][1]['summary'])"]},{"cell_type":"markdown","metadata":{"id":"e0mPgsfNb1TT"},"source":["<mark> Output of Pre-Trained model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Y54GOYkZaX77"},"outputs":[],"source":["index = 200\n","dialogue = dataset['test'][index]['dialogue']\n","summary = dataset['test'][index]['summary']\n","\n","prompt = f\"\"\"\n","Summarize the following conversation.\n","\n","{dialogue}\n","\n","Summary:\n","\"\"\"\n","\n","inputs = tokenizer(prompt, return_tensors='pt')\n","\n","print(inputs.keys())\n","print(inputs['input_ids'].shape)\n","display(inputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XF_iZ2JgawzU"},"outputs":[],"source":["model_output = original_model.generate(\n","        inputs[\"input_ids\"],\n","        max_new_tokens=200,\n","    )[0]\n","output = tokenizer.decode(\n","    model_output,\n","    skip_special_tokens=True\n",")\n","\n","dash_line = '-'.join('' for x in range(100))\n","print(dash_line)\n","print(f'INPUT PROMPT:\\n{prompt}')\n","print(dash_line)\n","print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n","print(dash_line)\n","print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"]},{"cell_type":"markdown","metadata":{"id":"gyhhmuyZbvdM"},"source":["<mark> 2 - Perform Full Fine-Tuning\n","\n","We need to convert the dialog-summary (prompt-response) pairs into explicit instructions for the LLM. Prepend an instruction to the start of the dialog with Summarize the following conversation and to the start of the summary with Summary.\n","\n","Then preprocess the prompt-response dataset into tokens and pull out their input_ids (1 per token)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6f3ZDR68bxgK"},"outputs":[],"source":["def tokenize_function(example):\n","    start_prompt = 'Summarize the following conversation.\\n\\n'\n","    end_prompt = '\\n\\nSummary: '\n","    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"dialogue\"]]\n","    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n","    example['labels'] = tokenizer(example[\"summary\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n","\n","    return example\n","\n","# The dataset actually contains 3 diff splits: train, validation, test.\n","# The tokenize_function code is handling all data across all splits in batches.\n","tokenized_datasets = dataset.map(tokenize_function, batched=True)\n","tokenized_datasets = tokenized_datasets.remove_columns(['id', 'topic', 'dialogue', 'summary',])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-d8xX961d24b"},"outputs":[],"source":["# To save some time in the lab, you will subsample the dataset:\n","\n","tokenized_datasets = tokenized_datasets.filter(lambda example, index: index % 100 == 0, with_indices=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3NYRxMAEd8IL"},"outputs":[],"source":["print(f\"Shapes of the datasets:\")\n","print(f\"Training: {tokenized_datasets['train'].shape}\")\n","print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n","print(f\"Test: {tokenized_datasets['test'].shape}\")\n","\n","print(tokenized_datasets)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"p48Htx-efIYk"},"outputs":[],"source":["# Now utilize the built-in Hugging Face Trainer class. Pass the preprocessed dataset with reference to the original model.\n","\n","output_dir = f'./dialogue-summary-training-{str(int(time.time()))}'\n","\n","training_args = TrainingArguments(\n","    output_dir=output_dir,\n","    learning_rate=1e-5,\n","    num_train_epochs=10,\n","    weight_decay=0.01,\n","    logging_steps=1,\n","    max_steps=50, # If set to a positive number, the total number of training steps to perform. Overrides num_train_epochs.\n","    report_to='none'  #To disable calling wandb white training\n",")\n","\n","trainer = Trainer(\n","    model=original_model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets['train'],\n","    eval_dataset=tokenized_datasets['validation']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nPVEhVH9fnid"},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1yHYNpGEkOKl"},"outputs":[],"source":["## Explitcitely save traned model to output directory\n","\n","trainer.model.save_pretrained(output_dir)\n","# trainer.tokenizer.save_pretrained(output_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NsEuggdTiV62"},"outputs":[],"source":["## Training a fully fine-tuned version of the model would take a few hours on a GPU. To save time, download a checkpoint of the fully fine-tuned model to use\n","## Create an instance of the AutoModelForSeq2SeqLM class for the instruct model:\n","\n","from transformers import AutoModelForSeq2SeqLM\n","instruct_model = AutoModelForSeq2SeqLM.from_pretrained(output_dir, torch_dtype=torch.bfloat16)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xtUC_3VCqAIH"},"outputs":[],"source":["import torch\n","\n","def move_all_tensors_to_cpu():\n","    \"\"\"Moves all tensors currently on CUDA to the CPU.\"\"\"\n","    for obj in globals().values():\n","        if isinstance(obj, torch.Tensor) and obj.device.type == 'cuda':\n","            obj.cpu()  # Moves the tensor to CPU\n","\n","# Call the function to move all CUDA tensors to CPU\n","move_all_tensors_to_cpu()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3vsOLaLAikJ0"},"outputs":[],"source":["# Evaluate the Model Qualitatively (Human Evaluation)\n","\n","index = 200\n","dialogue = dataset['test'][index]['dialogue']\n","human_baseline_summary = dataset['test'][index]['summary']\n","\n","prompt = f\"\"\"\n","Summarize the following conversation.\n","\n","{dialogue}\n","\n","Summary:\n","\"\"\"\n","\n","inputs = tokenizer(prompt, return_tensors=\"pt\")\n","\n","original_model_outputs = original_model.generate(\n","        inputs[\"input_ids\"],\n","        max_new_tokens=200,\n","    )[0]\n","original_model_text_output = tokenizer.decode(\n","    model_output,\n","    skip_special_tokens=True\n",")\n","\n","# instruct_model_outputs = instruct_model.generate(\n","#     inputs[\"input_ids\"],\n","#     max_new_tokens=200,\n","#     )[0]\n","# instruct_model_text_output = tokenizer.decode(\n","#     instruct_model_outputs,\n","#     skip_special_tokens=True\n","#     )\n","\n","# print(dash_line)\n","# print(f'BASELINE HUMAN SUMMARY:\\n{human_baseline_summary}')\n","# print(dash_line)\n","# print(f'ORIGINAL MODEL:\\n{original_model_text_output}')\n","# print(dash_line)\n","# print(f'INSTRUCT MODEL:\\n{instruct_model_text_output}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"otrabEo8noHe"},"outputs":[],"source":["import torch\n","\n","def get_tensor_names_on_devices():\n","    \"\"\"Returns a dictionary with lists of tensor names on CPU and CUDA devices.\"\"\"\n","    tensor_names_on_devices = {'cpu': [], 'cuda': []}\n","\n","    for name, obj in globals().items():  # Use .items() to get names\n","        if isinstance(obj, torch.Tensor):\n","            if obj.device.type == 'cpu':\n","                tensor_names_on_devices['cpu'].append(name)\n","            elif obj.device.type == 'cuda':\n","                tensor_names_on_devices['cuda'].append(name)\n","\n","    return tensor_names_on_devices\n","\n","# Get the tensor names on each device\n","tensor_names_on_devices = get_tensor_names_on_devices()\n","\n","# Print the lists\n","print(\"Tensor names on CPU:\", tensor_names_on_devices['cpu'])\n","print(\"Tensor names on CUDA:\", tensor_names_on_devices['cuda'])"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[],"authorship_tag":"ABX9TyOvQYWqG3aO0eNFf3DBJL1B"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}